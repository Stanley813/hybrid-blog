---
layout: post
title: Openshift Core Concepts
---

Container and Images
> The basic unit of OpenShift applications is the container. A Linux container provides a lightweight mechanism for isolating running processes so that they interact only with their designated resources. Many application instances can be running in containers on a single host without visibility into each other’s processes, files, networks, and other resources. Typically, each container provides a single service, often called a microservice. Examples include a web server or a database, although containers can be used for arbitrary workloads.While the Linux kernel has provided support for container technologies for years, more recently the Docker project has developed a convenient management interface for Linux containers on a host. OpenShift and Kubernetes add the ability to orchestrate Docker containers across multiple hosts.Docker containers are based on Docker images. A Docker image is a binary file that includes all the requirements for running a single Docker container, as well as metadata describing its needs and capabilities. Think of it as a packaging technology. Docker containers have access only to the resources defined in the image, unless you give the container additional access when creating it. By deploying the same image in multiple containers across multiple hosts and load balancing between them, OpenShift provides redundancy and horizontal scaling for a service packaged into an image.You can use Docker directly to build images. OpenShift also supplies builders that assist with creating an image by adding your code or configuration to existing images.

Pod and Services
>OpenShift leverages the Kubernetes concept of a pod. A pod is a collection of one or more containers deployed together on one host, and the smallest compute unit that can be defined, deployed, and managed.
Pods are the rough equivalent of OpenShift gears, with containers the rough equivalent of cartridge instances. Each pod is allocated its own internal IP address, therefore owning its entire port space, and containers within pods can share their local storage and networking.
Pods have a life cycle: They are defined, then assigned to run on a node, and then run until their containers exit or they are removed for some other reason. Pods, depending on policy and exit code, may be removed after their containers exit, or they may be retained to enable access to their containers' logs.
OpenShift treats pods as largely immutable—changes cannot be made to a pod definition while the pod is running. OpenShift implements changes by terminating an existing pod and recreating it with modified configurations or base images. Pods are also treated as expendable, and do not maintain state when destroyed or re-created. Therefore, pods are usually managed by higher-level controllers, rather than directly by users.
A Kubernetes service acts as an internal load balancer. It identifies a set of replicated pods in order to proxy the connections it receives to them. Backing pods can be added to or removed from a service arbitrarily while the service remains available, enabling anything that depends on the service to refer to it at a consistent internal address.
Services are assigned an IP address and port pair that, when accessed, proxy to an appropriate backing pod. A service uses a label selector to find all the running containers that provide a certain network service on a certain port.
